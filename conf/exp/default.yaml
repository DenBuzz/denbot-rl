ray_init:
  ignore_reinit_error: true
  local_mode: false

algorithm:
  base_config:
    _target_: ray.rllib.algorithms.ppo.PPOConfig

  training:
    train_batch_size_per_learner: 1028
    minibatch_size: 256
    vf_loss_coeff: 0.8

  env_runners:
    num_env_runners: 4

  # resources:
  #   num_gpus: 1

  learners:
    num_learners: 0  # often faster to just train on the driver
    # num_gpus_per_learner: 1

  multi_agent:
    policy_mapping_fn:
      _target_: hydra.utils.get_method
      path: rllib.build_config.denbot_map
run_config:
  checkpoint_config:
    num_to_keep: 5
    checkpoint_frequency: 10
    checkpoint_at_end: true
